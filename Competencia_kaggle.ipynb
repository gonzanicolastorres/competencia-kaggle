{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diplodatos Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present this peace of code to create the baseline for the competition, and as an example of how to deal with these kind of problems. The main goals are that you:\n",
    "\n",
    "1. Learn\n",
    "1. Try different models and see which one fits the best the given data\n",
    "1. Get a higher score than the given one in the current baseline example\n",
    "1. Try to get the highest score in the class :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(train_data_fname, test_data_fname):\n",
    "    df_train = pd.read_csv(train_data_fname)\n",
    "    df_train['is_train_set'] = 1\n",
    "    df_test = pd.read_csv(test_data_fname)\n",
    "    df_test['is_train_set'] = 0\n",
    "\n",
    "    # we  get the TripType for the train set. To do that, we group by VisitNumber and\n",
    "    # then we get the max (or min or avg)\n",
    "    y = df_train.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).max().TripType\n",
    "\n",
    "    # we remove the TripType now, and concat training and testing data\n",
    "    # the concat is done so that we have the same columns for both datasets\n",
    "    # after one-hot encoding\n",
    "    df_train = df_train.drop(\"TripType\", axis=1)\n",
    "    df = pd.concat([df_train, df_test])\n",
    "    \n",
    "    # the next three operations are the ones we have just presented in the previous lines\n",
    "    \n",
    "    ### Creamos la variable cantidad de productos por departamento que contiene cada tipo de viaje\n",
    "    \n",
    "    #Department_products=dict(df.groupby('DepartmentDescription')['Upc'].count())\n",
    "    #df['products_department']=df['DepartmentDescription'].apply(lambda x:Department_products.get(x))\n",
    "    \n",
    "    # drop the columns we won't use (it may be good to use them somehow)\n",
    "    df = df.drop([\"Upc\", \"FinelineNumber\"], axis=1)\n",
    "    \n",
    "    # Creamos la variable cantidad de departamentos visitados\n",
    "    Total_Dep = df.groupby('VisitNumber').DepartmentDescription.nunique().reset_index(name='Total_Dep')\n",
    "\n",
    "    # one-hot encoding for the DepartmentDescription\n",
    "    df = pd.get_dummies(df, columns=[\"DepartmentDescription\"], dummy_na=True)\n",
    "    \n",
    "    # Unimos la variable Total_Dept al DF\n",
    "    df = pd.merge(df, Total_Dep, on='VisitNumber')\n",
    "    \n",
    "    # now we add the groupby values\n",
    "    df = df.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).sum()\n",
    "    \n",
    "    # Creamos la variable \"fin de semana\"\n",
    "    df['Weekend'] = df['Weekday'].apply(lambda x : x in ('Saturday', 'Sunday'))\n",
    "    df['Weekend'] = df['Weekend'].astype(int)\n",
    "    \n",
    "    # We do one-hot encoding for the Weekday\n",
    "    df = pd.get_dummies(df, columns=[\"Weekday\"], dummy_na=True)\n",
    "    \n",
    "    ### Hacemos one-hot encoding para cantidad de departamentos visitados - no es relevante, bajo el puntaje.\n",
    "    # df = pd.get_dummies(df, columns=[\"Total_Dep\"], dummy_na=True)\n",
    "    \n",
    "    ### Creamos variable para \"compras negativas\"\n",
    "    df['Neg_purch'] = df['ScanCount'].apply(lambda x : x <=0)\n",
    "    df[\"Neg_purch\"] = df[\"Neg_purch\"].astype(int)\n",
    "    \n",
    "    ### Creamos variable para mas de 8 unidades  compradas (promedio del DF)\n",
    "    #df['more_8'] = df['ScanCount'].apply(lambda x : x >=8)\n",
    "    #df[\"more_8\"] = df[\"more_8\"].astype(int)\n",
    "    \n",
    "    ### Hacemos one-hot encoding para cantidad de productos comprados - No mejora el desempe√±o.\n",
    "    #df = pd.get_dummies(df, columns=[\"ScanCount\"], dummy_na=True)\n",
    "    \n",
    "    \n",
    "    # get train and test back\n",
    "    df_train = df[df.is_train_set != 0]\n",
    "    df_test = df[df.is_train_set == 0]\n",
    "    \n",
    "    X = df_train.drop([\"is_train_set\"], axis=1)\n",
    "    yy = None\n",
    "    XX = df_test.drop([\"is_train_set\"], axis=1)\n",
    "\n",
    "    return X, y, XX, yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, XX, yy = transform_data(\"https://raw.githubusercontent.com/DiploDatos/AprendizajeSupervisado/master/practico/data/train.csv\", \"https://raw.githubusercontent.com/DiploDatos/AprendizajeSupervisado/master/practico/data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training dataset into train and \"validation\" \n",
    "# (we won't be using validation set in this example, because of the cross-validation;\n",
    "# but it could be useful for you depending on your approach)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results dataframe is used to store the computed results\n",
    "results = pd.DataFrame(columns=('clf', 'best_acc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# we will use a DesicionTree to classify and GridSearch to determine the parameters\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tree_param = {'criterion':('gini', 'entropy'), 'min_samples_leaf':(4,5,8,15),\n",
    "              'min_samples_split':(25,100,150)}\n",
    "tree = DT(random_state=42)\n",
    "tree_clf = GridSearchCV(tree, tree_param, cv=3, scoring='accuracy') #scoring='balanced_accuracy')\n",
    "tree_clf.fit(X_train, y_train)\n",
    "best_tree_clf = tree_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree accuracy:  0.638299232736573\n",
      "DecisionTreeClassifier(min_samples_leaf=8, min_samples_split=100,\n",
      "                       random_state=42)\n",
      "The best classifier so far is: \n",
      "DecisionTreeClassifier(min_samples_leaf=8, min_samples_split=100,\n",
      "                       random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print('Best Decision Tree accuracy: ', tree_clf.best_score_)\n",
    "print(best_tree_clf)\n",
    "results = results.append({'clf': best_tree_clf, 'best_acc': tree_clf.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_acc'].idxmax()]['clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 100}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_tree = results.clf.iloc[0].predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_tree = pd.DataFrame(list(zip(XX.VisitNumber, yy_tree)), columns=[\"VisitNumber\", \"TripType\"])\n",
    "submission_tree.to_csv(\"../competencia-kaggle/submission_tree.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest accuracy:  0.638299232736573\n",
      "RandomForestClassifier(min_samples_leaf=3, min_samples_split=100,\n",
      "                       random_state=42)\n",
      "The best classifier so far is: \n",
      "RandomForestClassifier(min_samples_leaf=3, min_samples_split=100,\n",
      "                       random_state=42)\n"
     ]
    }
   ],
   "source": [
    "forest_param = {'criterion':('gini', 'entropy'), 'min_samples_leaf':(3,4,5),\n",
    "              'min_samples_split':[100]}\n",
    "forest = RF(random_state=42)\n",
    "forest_clf = GridSearchCV(forest, forest_param, cv=3, scoring='accuracy') #scoring='balanced_accuracy')\n",
    "forest_clf.fit(X_train, y_train)\n",
    "best_forest_clf = forest_clf.best_estimator_\n",
    "print('Best Random Forest accuracy: ', tree_clf.best_score_)\n",
    "print(best_forest_clf)\n",
    "results_rf = results.append({'clf': best_forest_clf, 'best_acc': forest_clf.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results_rf.loc[results_rf['best_acc'].idxmax()]['clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_leaf=3, min_samples_split=100,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest=RF(random_state=42, criterion='gini', min_samples_leaf=3, min_samples_split= 100)\n",
    "forest.fit(X=X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rf=forest.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6656720871251678"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, y_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_rf=forest.predict(XX)\n",
    "submission_rf = pd.DataFrame(list(zip(XX.VisitNumber, yy_rf)), columns=[\"VisitNumber\", \"TripType\"])\n",
    "submission_rf.to_csv(\"../competencia-kaggle/submission_rf.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='poly', random_state=42)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suport=SVC(random_state=42, kernel='poly')\n",
    "suport.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
